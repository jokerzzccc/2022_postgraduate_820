#   目录

[toc]

# 操作系统

时间：2021-10

目的：考研（820）



# 一、操作系统基本概念

## 1.1 操作系统的基本概念

1. **计算机系统**可自下而上大致分为4部分：硬件、操作系统、应用程序和用户。
2. **操作系统**的概念：
3. 操作系统时计算机系统中**最基本的软件**。
4. 操作系统的**基本特征**：
   1. 并发：
   2. 共享：
   3. 虚拟：
   4. 异步：
   5. 注意：其中**最基本的特征**是：**并发和共享**。
5. 操作系统的**功能（作用）**：（可分为三个放面）
   1. 操作系统作为**计算机系统资源的管理者**：（本书学习的重点）
      1. 处理机管理
      2. 存储器管理
      3. 文件管理
      4. 设备管理
   2. 操作系统作为**用户与计算机硬件系统之间的接口**：（为了**方便**用户适用操作系统）
      1. 命令接口
      2. 程序接口
   3. 操作系统作为**扩充机器**：



## 1.2 操作系统的**发展与分类**：

1. 手工操作阶段（此阶段无操作系统）
2. 批处理阶段（操作系统开始出现）
   1. 概念：
   2. 目的：
   3. 分类：
      1. 单道批处理系统
         1. 解决的问题：为了解决人机矛盾，及 CPU 和 I/O 设备之间速度不匹配的矛盾。
         2. 主要特点：
            1. 自动性
            2. 顺序性
            3. 单道性
      2. 多道批处理系统
         1. 解决的问题：为了进一步提高资源的利用率和系统的吞吐量。
         2. 主要特点：
            1. 多道。
            2. 宏观上并行
            3. 微观上串行
   4. 优点：
      1. 资源利用率高
      2. 系统吞吐量大
   5. 缺点：
      1. 用户响应时间较长；
      2. 不提供人机交互能力，
3. **分时操作系统**
   1. 概念：把处理器的运行时间分成很短的**时间片**，按时间片轮流把处理器分配各联机作业适用。
   2. 解决的问题：很好的解决了**人机交互**的问题。
   3. **主要特征**：
      1. 同时性：（多路性）
      2. 交互型：
      3. 独立性
      4. 及时性
4. **实时操作系统**
   1. 目的：为了能在某个时间限制内完成某些紧急任务而不需要时间片排队，而诞生了实时操作系统。
   2. 分类：
      1. 硬实时系统：某个动作必须绝对地在规定的时刻（或规定的时间范围）发生。
      2. 软实时系统：能够接受偶尔违反时间 （比如：机票订购系统）
   3. 主要特点：
      1. 及时性
      2. 可靠性
   4. 
5. **网络操作系统**：
   1. 概念：
   2. 最主要的特点：是网络中各种资源的共享和各台计算机之间的通信。
6. **分布式操作系统**：
   1. 概念：
   2. 主要特点：
      1. 分布性
      2. 并行性
   3. 分布式系统与网络操作操作系统的**本质不同**是：
      1. 分布式操作系统中的若干计算机相互协同完成同一任务。
7. 个人计算机操作系统：



## 1.3 操作系统的运行环境

### 1.3.1 操作系统的运行机制

- 计算机系统中，通常 CPU 执行两种不同性质的程序：
  - 操作系统内核程序：
  - 用户自编程序（应用程序）：
- 注意：内核程序是用户程序的**管理者**；



1. **特权指令**：
   1. 指计算机中不允许用户直接使用的指令。
   2. 比如：I/O 指令、置中断指令，存取用于内存保护的寄存器、送程序状态字道程序状态字寄存器等的指令。
2. 在具体实现上，CPU 的**状态划分**为：
   1. 用户态（目态）：
   2. 核心态（又称管态、内核态）：
3. 用户程序运行在用户态；操作系统内核程序运行在核心态。
4. **操作系统的内核**包括：
   1. 时钟管理：
   2. 中断机制
   3. 原语
   4. 系统控制的数据结构及处理
      1. 进程管理：进程状态管理、进程调度和分配、创建与撤销进程控制块等。
      2. 存储器管理：存储器的空间分配和回收、内存信息保护程序、代码对换程序等。
      3. 设备管理：缓冲区管理，设备分配和回收等。



### 1.3.2 中断和异常的概念

1. **中断**：也称为外中断
   1. 概念：指**来自 CPU 执行指令以外**的事件的发生。比如：设备发出的 I/O 结束中断。
   2. 特点：通常，这类中断与当前处理机运行的程序无关。
2. **异常**：也称为内中断
   1. 概念：指**源自 CPU 执行指令内部**的事件发生。比如：程序的非法操作码，地址越界，算术溢出，虚存系统的缺页，及专门的陷入指令等引起的事件。 
   2. 特点：异常的处理一般要依赖于**当前程序的运行现场**。而且**异常不能被屏蔽**，一旦出现应立即处理。
3. 内中断于外中断的**联系与区别**：
   1. 内中断：
      1. 自愿中断：指令中断
      2. 强迫中断：
         1. 硬件故障
         2. 软件中断
   2. 外中断：（强迫中断）
      1. 外设请求
      2. 人的干预
4. **中断处理的过程**：



### 1.3.3 系统调用

1. 系统调用的**概念**：是指用户在程序中调用操纵系统所提供的一些子功能，系统调用可视为特殊的公共子程序。
2. 系统调用**按功能分类**大致为如下5类：
   1. 设备管理
   2. 文件管理
   3. 进程控制 
   4. 进程通信
   5. 内存管理
3. 注意：
   1. **系统调用的处理**需要由操作系统内核程序负责完成，要**运行在核心态**。
   2. 用户程序可以执行**陷入指令（又称访管指令或 trap 指令）**来发起系统调用，请求操作系统提供服务。 
4. **从用户态转向核心态**的例子：
   1. 用户程序要求操作系统的服务，即系统调用。
   2. 发生一次中断。
   3. 用户程序中产生了一个错误状态。
   4. 用户程序中企图执行一条特权指令。
   5. 从核心态转向用户态由一条指令实现，这条指令也是特权指令，一般是中断返回指令。
5. 注意：
   1. 由用户态到核心态，不仅是状态需要切换，而且所用的堆栈也可能需要由用户堆栈切换为系统堆栈，但这个系统堆栈也是属于该进程的。
   2. 若程序的运行由用户态转到核心态，则会用到**访管指令**，访管指令是在用户态使用的，所以它不可能是**特权指令**。





# 二、进程管理

## 2.1 进程与线程

### 2.1.1 进程的基本概念

1. 引入进程的**目的**：
   1. 以便更好地描述和控制程序的并发执行，实现操作系统的并发性和共享性。
2. **进程控制块（PCB）**：为了使参与并发执行的程序能独立运行，配置的一个专门的数据结构。
3. 进程实体（进程映像）：由 程序段、相关数据段、PCB 三部分组成。
4. 创建进程：实质上就是创建进程映像中的PCB。
5. 撤销进程：实质上是撤销 PCB。
6. 注意：
   1. 进程是**动态**的，进程映像是静态 的。
   2. PCB 是进程存在的唯一标志。
   3. 进程是一个动态的、过程的概念。
7. **进程的定义**：是进程实体的运行过程，是系统进行资源分配和调度的基本单位。
8. 进程 的**特征**：
   1. 动态性
   2. 并发性
   3. 独立性
   4. 异步性
   5. 结构性
9. 进程的**状态与转换**：
   1. 运行态：
   2. 就绪态
   3. 阻塞态
   4. 创建态
   5. 结束态
10. 做题总结：
    1. 当一个进程独占处理器顺序执行时，具有两个特性：封闭性和可再现性。



### 2.1.2 进程控制

- 进程控制 **主要功能**：对系统中所有的进程的管理：创建、撤销、实现进程状态转换等。



1. **原语**：进程控制用的程序段，称为原语。
   1. 原语的特点：执行期间不允许中断，是一个不可分割的基本单位。
2. 进程的**创建**：
   1. 父进程
   2. 子进程
   3. 创建原语：
3. 进程的**终止**：
   1. 撤销原语：
4. 进程的阻塞和唤醒：
   1. 阻塞原语：
   2. 唤醒原语：
5. 进程的切换。
6. 注意：
   1. **调度和切换**的区别：
      1. 调度：是指决定分配资源给哪个进程的行为，是一种**决策**行为。
      2. 切换：是指实际分配的行为，是**执行**行为。



### 2.1.3 进程的组织

1. 进程控制块：
2. 程序段：
3. 数据段：

### 2.1.4 进程的通信

1. 共享存储：
2. 消息传递：
3. 管道通信：



### 2.1.5 线程的概念

1. 引入**进程的目的**：
   1. 更好地使多道程序并发执行，提高资源利用率和系统吞吐量。
2. 引入**线程的目的**：
   1. 减小程序在并发执行时所付出的时空开销，提供操作系统的并发性能。
3. **线程与进程的比较**：
   1. 调度：
      1. 线程是**独立调度**的基本单位。
      2. 进程是**拥有资源**的基本单位。
   2. 拥有资源：
   3. 并发性：
   4. 系统开销：
   5. 地址空间和其它资源：
   6. 通信方面：
4. 线程的**属性**：
5. 线程的**分类**：
   1. 用户级线程
   2. 内核级线程
6. 线程模型：
   1. 多对一模型：
      1. 将多个用户级线程映射到一个内核级线程。
   2. 一对多模型：
      1. 将每个用户级线程映射到多个内核级线程。
   3. 多对多模型：
      1. 将 n 个用户级线程映射到 m 个内核级线程， 要求 m < n。

## 2.2 处理机调度

### 2.2.1 调度的概念

1. **处理机调度**：对处理机进行分配，即从就绪队列中 按照一定的算法选择一个进程，并将处理机分配给它运行，以实现进程地并发执行。
2. **调度的层次**：（三级调度）
   1. 作业调度：（高级调度）
   2. 中级调度：（内存调度）
   3. 进程调度：（内存调度）
      1. ​	进程调度是**最基本的**，最不可或缺的。
3. 调度的时机与切换过程：
   1. **不能进行**进程的调度与切换的情况：
   2. **应该进行**进程调度与切换的情况：



### 2.2.2 进程调度的方式

1. 进程调度的方式：（两种）
   1. 非剥夺调度方式（非抢占方式）：
      1. 适用于大多数的批处理系统，不能用于分时系统和绝大多数的实时系统。
   2. 剥夺调度方式（抢占方式）：



### 2.2.3 调度的基本准则

1. CPU 利用率：
2. 系统吞吐量：
   1. 定义：单位时间内 CPU 完成作业的数量。
3. 周转时间：
   1. 周转时间 = 作业完成时间 - 作业提交时间
   2. 平均周转时间：
   3. 带权周转时间：= 作业周转时间 / 作业实际运行时间
4. 等待时 间：
5. 响应时间：



### 2.2.4 典型的调度算法

- ==典型的调度算法（6个）==：
  1. 先来先服务（FCFS）算法
  2. 短作业优先（SJF) 调度算法
  3. 优先级调度算法
  4. 高响应比算法
  5. 时间片轮转调度算法
  6. 多级反馈队列算法



1. 先来先服务（FCFS）算法：
   1. 即可用于作业调度，也可用于进程调度。
   2. 属于 不可剥夺算法。
   3. 特点：
      1. 算法简答，但效率低；
      2. 对长作业有利，对短作业不利；
      3. 有利于 CPU 繁忙型作业，不利于 I/O 繁忙型作业。
2. 短作业优先（SJF) 调度算法：
   1. 对长作业不利，产生长作业长期不被调度（**“饥饿”现象**）。
   2. SJF 调度算法的平均等待时间、平均周转时间**最短**。
3. 优先级调度算法：
4. 高响应比算法：
   1. 响应比 $Rp$ = (等待时间 + 要求服务时间) / 要求服务时间
5. 时间片轮转调度算法：
   1. 适用于分时系统。
   2. 
6. 多级反馈队列算法：
   1. 综合了 时间片轮转调度算法与优先级调度算法。

## 2.3 进程同步  

### 2.3.1 进程同步的概念

1. **临界资源**：
2. **同步**：
   1. 同步的概念：
   2. 同步机制遵循的**原则**：
      1. 空闲让进：
      2. 忙则等待：
      3. 有限等待：
      4. 忙则等待：
3. **互斥**：
4. 

### 2.3.2 实现临界区互斥的基本方法（考纲无）

- 总共分为两类：
  - 软件实现方法
  - 硬件实现方法



1. 软件实现方法：
2. 硬件实现方法：

### 2.3.3 信号量

- 信号量机制用来解决互斥与同步问题。只能被两个标准原语 wait(S) 和 signal(S) 访问，也可记为 “ P 操作” 和 “ V 操作”。
- 信号量分类：
  - 整型信号量
  - 记录型信号量：



1. 利用**信号量实现同步**：
2. 利用**信号量实现互斥**：
3. 

### 2.3.4 管程

1. 管程的**定义**：
   1. 这个代表**共享资源的数据结构**，以及由对该共享数据结构实施操作的一组过程所组成的**资源管理程序**，称为管程（ monitor)。
   2. 同时管程 提供了**条件变量**，可以让程序员灵活地**实现进程同步**。
2. 管程由**4部分组成**：
   1. 管程的名称；
   2. 局部与管程内部的共享数据结构说明；
   3. 对该数据结构进程操作的一组过程（或函数）；
   4. 对局部于管程内部的共享数据设置初始值的语句。
3. 管程的**性质**：（管程像一个面向对象中的**类**）
   1. 管程把对共享资源的操作封装起来，管程内的共享数据结构只能被管程内的过程所访问。一个进程只有通过调用管程内的过程才能进入管程访问共享资源。
   2. 每次只允许一个进程进入管程，从而实现进程互斥。各个进程只能串行执行管程内的过程，这一特性保证了进程“互斥”访问共享数据结构 s 。
4. **条件变量**（condition）：
   1. 定义：当一个进程进入管程后被阻塞，直到阻塞的原因解除时，在此期间，如果该进程不释放管程，那么其它进程无法进入管程。为此将**阻塞原因**定义为条件变量。
   2. 性质：
      1. 每个条件变量保存了一个等待队列，
      2. 对条件变量只能进行两种操作：wait 和 signal 
         1. **x.wait**：当 x 对应的条件不满足时，正在调用管程的进程调用 x.wait 将自己插入 x 条件的等待队列，并释放管程。此时，其它进程可以使用该股管程。
         2. **x.signal**：x 对应的条件发生了变化，则调用 x.signal ，唤醒一个因 x 条件而阻塞的进程。
   3. **条件变量与信号量的比较**：
      1. 相似点：条件变量的 wait/signal 操作类似于信号量的 P/V 操作，可以实现进程的阻塞与唤醒。
      2. 不同点：
         1. 条件变量是“没有值”的，仅实现了“排队等待”的功能；
         2. 而信号量是“有值”的，信号量的值反映了剩余资源数，而在管程中，剩余资源数用共享数据结构记录。

### 2.3.5 经典同步问题

#### 1、**生产者与消费者问题**：

1. **问题描述**：

   1. 一组生产者进程和一组消费者进程共享一个初始为空、大小为 n 的**缓冲区**；
   2. 只有缓冲区没满时，生产者才能把消息放入缓冲区，否则必须等待；
   3. 只有缓冲区不空时，消费者才能从中取出消息，否者必须等待；
   4. 由于缓冲区是临界资源，它只允许一个生产者放入消息，或者一个消费者从中取出消息。

2. 关系分析：

   1. 生产者和消费者对缓冲区的访问时**互斥**关系；
   2. 同时，只有生产者生产之后消费者才能消费，它们也是同步关系。

3. **信号量的设置**：

   1. 信号量 mutex ：作为互斥信号量，用于控制互斥访问缓冲池，初始值为 1；
   2. 信号量 full ：用于记录当前缓冲池中的 **满**缓冲区数，初始值为0；
   3. 信号量 empty：用于记录当前缓冲池中的**空**缓冲区数，初值为 n;

4. ```c
   // 简单的生产者-消费者进程的描述如下：
   semaphore  mutex = 1;
   semaphore full = 0;
   semaphore empty = n;
   // 生产者进程
   producer(){
   	while(1){
   		produce an item in nextp;
           P(empty);
           P(mutex);
           add nextp to buffer;
           V(mutex);
           V(full);
   }
   }
   // 消费者进程
   consumer(){
       while(1){
           P(full);
           P(mutex);
           remove an item from buffer;
           V(mutex);
           V(empty);
           consume the item;
       }
   }
   ```

5. 

#### 2、**读者-写者问题**：

1. **问题描述**：有读者和写者两组并发进程，共享一个文件。

2. 问题要求：

   1. 允许多个读者可以同时对文件执行读操作；
   2. 只允许一个写者往文件中写信息；
   3. 任意一写者在完成操作之前，不允许其它读者或者写者工作；
   4. 写者执行写操作之前，应让已有的读者和写者全部退出。

3. 关系分析：

   1. 读者与写者互斥；
   2. 写者和写者互斥；
   3. 读者和读者之间不存在互斥问题，

4. 解决问题的关键：添加一个计数器，用来判断当前是否有读者读文件。

   1. 不同读者对计数器的访问应该是互斥的。

5. **信号量设置**：

   1. 信号量 count ：计数器，用于记录当前读者的数量，初始为0；
   2. 信号量 mutex ：互斥信号量，用于保护更新 count 变量时的互斥，初始为1；
   3. 信号量 rw ：用于保证读者和写者的互斥访问，初始为1。

6. **读进程优先**的程序如下：

   1. ```c
      // 读进程优先的 读者与写者问题
      int count = 0;
      semaphore mutex = 1;
      semaphore rw = 1;
      // 写者进程
      writer(){
          while(1){
              P(rw);
              writing;
              V(rw);
          }
      }
      // 读者进程
      reader(){
          while(1){
              P(mutex);
              if (count == 0)
                  P(rw);
              count++;
              V(mutex);
              P(mutex);
              count--;
              if (count == 0)
                  V(rw);
              V(mutex);
          }
      }
      ```

   2. 读进程优先，会存在 **写进程 “饿死”**的情况。

7. **写进程优先**的程序如下：

   1. 增加一个信号量 w ，用于实现 写优先。在 reader() 与 writer () 中各增加一对 PV 操作。

   2. ```c
      // 读进程优先的 读者与写者问题
      int count = 0;
      semaphore mutex = 1;
      semaphore rw = 1;
      semaphore w = 1; //用于实现写进程优先
      // 写者进程
      writer(){
          while(1){
              P(w); // 在无写进程请求时进入
              P(rw);
              writing;
              V(rw);
              V(w); // 回复对共享文件的访问
          }
      }
      // 读者进程
      reader(){
          while(1){
              P(w); // 在无写进程请求时进入
              P(mutex);
              if (count == 0)
                  P(rw);
              count++;
              V(mutex);
              V(w);
              P(mutex);
              count--;
              if (count == 0)
                  V(rw);
              V(mutex);
          }
      }
      ```

   3. 

#### 3、**哲学家进餐问题**：

1. **问题描述**：一张圆桌边上坐着5名哲学家，每两名哲学家中间一个筷子，两根筷子中间是一碗米饭。

2. **信号量设置**：

   1. 互斥信号量数组 chopstick[5] = {1,1,1,1,1}：用于对五个筷子的互斥访问；
   2. 哲学家按顺序编号为 0~4，哲学家 i 左边筷子的编号为 i ，右边筷子的编号为 (i + 1) % 5

3. 避免死锁的方法：对哲学家进程施加一些限制。

   1. 方法一：至多允许4名哲学家进餐；
   2. **方法二**：仅当一名哲学家左右两边的筷子都可用时，才允许他抓筷子；（**下面程序就是这个方法**）
   3. 方法三：对哲学家编号，奇数号哲学家先拿左边筷子，再拿右边筷子，而偶数号刚好相反。

4. 哲学家进餐程序如下：（使用上面的第二种方法）

   1. ```c
      // 哲学家进餐程序
      semaphore chopstick[5] = {1,1,1,1,1}
      semaphore mutex = 1; // 设置取筷子的信号量
      Pi(){ // i 号哲学家的进程
          do{
              P(mutex);
              P(chopstick[i]);
              P(chopstick[(i + 1)%5]);
              V(mutex);
              eating;
              V(chopstick[i]);
              V(chopstick[(i + 1)%5]);
              think;
          }while(1);
      }
      ```

   2. 

1. 吸烟者问题：（考纲无）



#### 4、PV 大题的做题思路总结

> PV 大题的做题步骤

1. 分析进程
2. 分析资源
3. 分析关系，同步与互斥
4. 考虑是否是几个典型问题中的一个的变体
5. 设置信号量





## 2.4 死锁

### 2.4.1 死锁的基本概念

1. 死锁**定义**：是指多个进程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都将无法推进。
2. 死锁产生的**原因（2）**：
   1. 系统资源的竞争：
   2. 进程推进顺序非法：
3. 死锁**产生的必要条件（4）**：
   1. 互斥：
   2. 不可剥夺：
   3. 请求并保持：
   4. 循环等待：



### 2.4.2 死锁的处理策略

- 死锁的处理策略，从三个大方面进行。

1. 死锁预防：
   1. 死锁预防：只需破坏死锁产生的四个必要条件之一即可。
      1. 破坏互斥：一般不破坏这个。
      2. 破坏不剥夺条件：
      3. 破坏请求并保持条件：运行前分配给它所需要的全部资源，资源未满足时，不投入运行。
      4. **破坏循环等待条件**：采用**顺序资源分配法**：
2. **死锁避免**：
3. 死锁的检测和解除：

### 2.4.3 死锁避免

- 死锁避免属于事先预防策略，在**资源动态分配过程中**，防止系统进入不安全状态，以避免发生死锁。

1. **系统安全状态**：
   1. 安全状态的定义：系统能按某种进程推荐顺序为每个进程 Pi 分配其所需要的资源，直至满足每个进程对资源的最大需求，使每个进程都可顺序完成。
   2. **安全序列**：处于安全状态的进程序列。
   3. 注意：
      1. 并非所有的不安全状态都是死锁状态，但当系统进入不安全状态后，便可能进入死锁状态；
      2. 反之，只要系统处于安全状态，系统便可避免进入死锁状态。
2. **银行家算法**：
   1. **数据结构**：
      1. 可利用资源向量 Available：
         1. 系统中现有的可分配的资源数。
      2. 最大需求矩阵 Max：
         1. 进程需要的最大资源数。
      3. 分配矩阵 Allocation :
         1. 当前已分配给每个进程的资源数。
      4. 需求矩阵 Need ：
         1. 每个进程接下来还需要多少资源。
      5. 总结：Need = Max - Allocation
         1. 一般 Max 矩阵和 Allocation 矩阵已知，求 Need 是第一步。
   2. **银行家算法**：
      1. 步骤：
   3. **安全性算法**：
      1. 步骤：
         1. 
   4. 

### 2.4.5 死锁的检测和解除

1. **资源分配图**：
   1. 请求边：
   2. 分配边：
2. **死锁定理**：
   1. 死锁定理含义：S 为死锁的的条件是，当且仅当 S 状态的**资源分配图是不可完全简化的**，该条件为 死锁定理。
   2. 可完全简化：若能消去图中所有的边。则称该图是可简化的。
   3. 简化方法：
      1. 找出资源分配图中，及不阻塞又不孤店的进程 Pi （即，找出一条有向边与它相连，且该有向边对应资源的**申请数量小于等于** 系统中已有的系统中已有的**空闲资源数量**），消除它所有的边。
      2. 最后，如果能消除所有的边，则是可完全简化的。
3. **死锁解除**：
   1. 资源剥夺法：
   2. 撤销进程法：
   3. 进程回退法

# 三、内存管理

## 3.1 内存管理的基本概念

1. 内存管理的**功能**：
   1. **内存空间的分配与回收**
   2. **地址转换**
   3. **内存空间的扩充**
   4. **存储保护**

## 3.2 程序的执行过程

将用户源程序变为可在内存中执行的程序的程序的**步骤**：

1. **编译**：
   1. 概念：
2. **链接**：
   1. 概念：
   2. 有三种方式：
      1. 静态链接
      2. 装入时动态链接
      3. 运行时动态链接
3. **装入**：
   1. 概念：
   2. 有三种方式：
      1. 绝对装入：
      2. 可重定位装入：又称 静态重定位
         - 在**装入时**一次完成
      3. 动态运行时装入：又称 动态重定位
         - 在**程序执行时**进行



> 编译



> 内存保护

两种方法：

1. CPU 设置一对**上、下限寄存器**
   1. 存放用户作业在主存中的下限和上限地址。
   2. 判断有无越界。
2. 采用**重定位寄存器（基址寄存器**） 和 **界地址寄存器（限长寄存器）**
   1. 重定位寄存器：含最小的物理地址值。
      - 用来 **加** 的。逻辑地址 加上 重定位寄存器的值，就得到物理地址。
   2. 界地址寄存器：含最大的逻辑地址值。
      - 用来 **比** 的。比较逻辑地址的值 与 界地址寄存器的值，判断是否越界。

## 3.3 交换与覆盖

- 作用：扩充内存
- 区别：
  - 交换：用在 **不同进程（作业）之间** 进行
  - 覆盖：用于 **同一程序或进程** 中
- 覆盖技术已曾历史，交换仍在活跃。

### 3.3.1 覆盖

1. 基本思想：
   1. 把用户空间分成一个固定区，和若干个覆盖区。
   2. 经常活跃的放在固定区，其余部分按调用关系分段。
   3. 首先将那些将要访问的段放在覆盖区，其它段放在外存储，在需要调用前，系统再将其调入覆盖区，替换覆盖区中原有的段。
2. 覆盖的特点：打破了必须将一个进程的全部信息装入主存后才能运行的限制。 

### 3.3.2 交换

1. 基本思想：
   1. 换出：把处于等待状态的程序从内存移到辅存，把内存空间腾出来，
   2. 换入：把准备好竞争 CPU 运行的程序从辅存移到内存

## 3.4 连续分配管理方式

- 连续分配方式：为一个用户程序分配一个连续的内存空间。
- 连续分配管理方式有三种：
  - 单一连续分配
  - 固定分区分配
    - 会长生**内部碎片**
  - 动态分区分配（可变分区分配）
    - 产生**外部碎片**：采用**紧凑（拼接）**的方式解决。
      - 紧凑：操作系统不时的对进程进行移动和整理。

### 3.4.1 单一连续分配

1. 性质：
   1. 优点：简单，无外部碎片，可以采用覆盖技术，不需要额外的技术支持。
   2. 缺点：只能用于单用户、单任务的操作系统，**有内部碎片**，存储器的利用率极低。

### 3.4.2 固定分区分配

1. 固定分区**划分分区**的方法（两种）：
   1. 分区大小相等
   2. 分区大小不等
2. 性质：
   1. 优点：可适用于多道程序设计的最简单的存储分配，无外部碎片。**有内部碎片**。
   2. 缺点：**有内部碎片**。不能实现多进程共享一个主存区，所以存储空间利用率低。

### 3.4.3 动态分区分配

1. 动态分区分配的**概念**：又称可变分区分配。这种分区方法不预先划分内存，而是在装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。



> 动态分区的分配策略

1. 首次适应（ First Fit ) 算法：
   1. 空闲分区以**地址递增**的次序链接。
2. 最佳适应 ( Best Fit) 算法：
   1. 空闲分区按**容量递增**的方式形成分区链
   2. 会有**最多的外部碎片**
3. 最坏适应 ( Worst Fit) 算法：又称 最大适应算法
   1. 空闲分区以**容量递减**的方式链接 
4. 邻近适应（Next Fit）算法（循环首次适应算法）：
   1. 概念：由首次适应算法演变来的，不同在于：分配内存时，从上次查找结束的位置开始继续查找。



## 3.5 非连续分配管理方式

非连续分配**定义**：允许一个程序分散地装入**不相邻的内存分区**。

分三种：

1. 基本分页存储管理方式
2. 基本分段储存管理方式
3. 段页式存储管理方式



**分类依据：**

1. 依据分区的大小是否固定：
   1. 分页存储（固定）
   2. 分段存储（不固定）
2. 根据运行作业时，是否要把**所有页面都装入内存才能运行**：
   1. 基本分页存储（需要所有）
   2. 请求分页存储（不需要所有）





#### 3.5.1 基本分页存储管理方式

1. 分页的**思想**：
   1. 把**主存**空间划分为大小相等且固定的**块**，块相对较小，作为主存的基本单位。
   2. 每个**进程**也以**块**为单位进行划分，
   3. 进程在**执行时**，**以块为单位**逐个申请主存中的块空间。
2. 不会有外部碎片，但是又内部碎片（页内碎片）
3. 分页存储的 **基本概念**：
   1. 页面和页面大小：
      1. 页：进程中的块
      2. 页框（页帧）：内存中的块
      3. 外存也以同样的单位进行划分，直接称为**块**。
      4. 页和页框一一对应。
   2. 地址结构：分页的逻辑地址结构有两部分
      1. 页号（P）：地址空间最多允许多少页
      2. 页内偏移量 （W）：决定 **每页大小**。
   3. 页表：
      1. 定义：系统为每个进程建立一张页表，它记录页面在内存中对应的物理块号。
      2. 页表一般存放在内存中。
      3. 页表项：两部分组成：第一部分，页号；第二部分，物理内存的块号。
         1. 页表由**页表项**组成。
         2. 页表项的第二部分与逻辑地址的第二部分共同组成**物理地址**。 
      4. 页表的作用：实现从页号到物理块号的地址映射。
4. 基本的地址变换机构：
   1. 地址变换机构的**任务**：将逻辑地址转换为内存中的物理地址。
   2. 页式管理中，地址空间式**一维**的。因为页面 L 大小是固定的。
   3. 
5. 具有**快表**的地址表换机构：
   1. **快表（TLB)(相关联存储器)** 概念：在地址变换机构中增设一个具有并行查找能力的高速缓冲存储器。
   2. 快表的**作用**：用来存放当前访问的若干页表项，以加速地址变换的过程。
   3. 以此对应，主存中的页表通常称为慢表。
   4. 如果所访问的页面在快表中，存取数据**仅一次**访存就可以实现。
6. **两级页表**：
   1. 
7. 分页管理方式的**特点**
   1. 从计算机的角度考虑，通过硬件机制实现，对用户完全透明，
   2. 目的式提供内存的利用率，较少碎片的产生，提升计算机的性能。

#### 3.5.2 基本分段存储管理方式

1. 分段的思想：
2. 不会有内部碎片
3. 分段管理的**特点**：
   1. 考虑了用户和程序员，
   2. 方便编程、信息保护和共享、动态增长、动态链接等多方面的需要。







#### 3.5.3 段页式存储管理方式

 

## 3.6 虚拟内存管理方式

### 3.6.1 虚拟内存的基本概念

1. **局部性原理** :
   1. 时间局部性：程序中的某条指令一旦执行，不久后该指令**可能再次执行**。
   2. 空间局部性：一旦程序访问了某个存储单元，不久后，其**附近的存储单元**也将**再被访问**。

2. **虚拟存储器的特征 **：
   1. 多次性：
   2. 对换性：
   3. 虚拟性：从逻辑上扩充内存。
3. **虚拟内存的实现方式：**
   1. **请求分页**存储管理：
   2. **请求分段**存储管理：
   3. **请求段页式**存储管理：
4. 虚拟内存技术实现需要的**硬件支持**：
   1. 一定容量的内存与外存
   2.  页表机制（或段表）：作为主要的数据结构。
   3. 中断机构：当用户程序要访问的部分尚未调入内存时，则产生中断。
   4. 地址变换机构：逻辑地址到物理地址的变换。



### 3.6.2 请求分页管理方式

1. 请求分页的**页表项**，相对于基本分页，增加了后四个字段：
   1. 页号：
   2. 物理块号：
   3. 状态位 P：
      1. 用于指示该页是否已经调入内存，
      2. 供**程序访问时**参考。
   4. 访问字段 A：
      1. 用于记录本页在一段时间内被访问过的次数，或者，已有多长时间未被访问。
      2. 供**置换算法换出页面时**参考。
   5. 修改位 M :
      1. 标识该页在调入内存后是否被修改过。
   6. 外存地址：
      1. 用于指出该页在外存上的地址，通常是物理块号，
      2. 供调入该页时参考。

### 3.6.3 页面置换算法

1. **最佳（OPT）置换算法**：
   1. 淘汰的页面：以后永久不使用的页面，或最长时间内不在访问的页面。
2. **先进先出（FIFO）算法 **： 
   1. 淘汰的页面：最早进入 内存的页面，即内存中驻留时间最久的页面。
   2. 会出现 **Belady 现象 ** ：所分配的物理块数增加，而页故障数不减反增的现象。 
3. **最近最久未使用（LRU）算法**: 
   1. 淘汰的页面：最近最长时间未访问过的页面
   2. 基于**堆栈**实现
   3. 特点：性能良好，但是需要 寄存器和栈的 **硬件支持**。
   4. 耗费高的原因：需要对所有的页进行排序。
4. **时钟（CLOCK）置换算法**：
   1. 简单的 CLOCK 算法，给每帧关联一个附加位，称为 **使用位（访问位）**。
      1. u = 0：最近未访问
   2. 改进的 CLOCK 算法：再增加一个 **修改位**。
      1. m = 0: 最近未修改
      2. **改进型 CLOCK 算法执行的操作步骤**：
         1. 从指针当前位置开始，扫描帧缓冲区。在这次扫描过程中，对使用位不做任何修改。选择遇到的第一个帧 （u=0,m = 0) 用于替换。
         2. 若第一步失败，则重新扫描，查找 (u = 0,m = 1) 的帧。选择遇到的第一个这样的帧用于替换。在这个扫描过程中，对每个跳过的帧，把它的使用为设置为0。
         3. 若第二步失败，则指针回到最初的位置，且集合中所有帧的使用位均为0。重复第一、二步，找到替换的帧。
   3. 淘汰的页面：替换时首选未变化的页面。（u=0,m = 0)->(u = 0,m = 1)



### 3.6.4 页面分配策略（考纲无）

> 考纲无这一节内容

1. 驻留集：
   1. 概念：给一个进程分配的物理页框的集合。
2. 常用的采用三种页面分配策略：
   1. 固定分配局部置换：
      1. 概念：为每个进程分配一定的数目的物理块，在整个运行期间都不改变；若进程运行中发生缺页，则只能从该进程在内存中的页面中选出一页换出，然后调入所需要的页面。
   2. 可变分配全局置换：
      1. 概念：为系统中的每个进程分配一定数目的物理块，操作系统自身也保持一个空闲物理块队列。当某进程缺页时，系统从空闲物理块队列中取出一个物理块分配给该进程，并将与调入的页装入其中。
      2. 性质：
         1. 这是最易于实现的物理块分配和置换策略。
         2. 优点：可以动态增加进程的物理块；
         3. 缺点：盲目地增加进程的物理块，导致系统多道程序的并发能力下降。
   3. 可变分配局部置换
      1. 概念：
   4. 总结（针对上面三种分配策略）：
      1. 固定与可变：是指分配给进程的物理块数。
3. 调入页面的时机：
   1. 预调页策略：运行前调入。
   2. 请求调页策略：运行期间调入，
4. 从何处调入页面：
   1. 文件区
   2. 对换区





### 3.6.5 抖动

1. **抖动概念**：在页面置换过程中，刚刚换出的页面马上又要换入主存；刚刚换入的页面马上又要换出主存。
2. 抖动**原因**：某个进程频繁访问的页面数目**高于**可用的物理页帧数。

 





# 四、文件管理

## 4.1 文件系统基础

- 前言：学习文件，可以把文件看作一种数据结构，需要学习它的逻辑结构，物理结构（文件的实现），以及操作（考研不学习）。
- **簇**：包含多个扇区。（看题意）



1. **文件**：文件是以计算机硬盘为载体的存储在计算机上的信息集合。
2. 注：
   1. 在系统运行时，计算机以进程为基本单位进行资源的调度与分配；
   2. 在用户进行的输入与输出中，则以文件为基本单位。
3. **文件系统**：当用户将文件用于程序的输入、输出 时，还希望可以访问文件、修改文件、保存文件等，实现**文件的维护管理**，需要操作系统提供一个文件管理系统。
   1. 文件系统的目的：实现用户的这些管理需求。
   2. 文件系统的**主要目标**：提高存储空间的利用率和减少存取时间。



### 4.1.1 文件的逻辑结构

1. **文件的逻辑结构**：从**用户观点**出发看到的文件的组织形式。
2. **文件的物理结构**：从**实现观点**出发看到的文件在外存上的存储组织形式。
3. 按**逻辑结构分类**，文件可以分为**两类**：
   1. 无结构文件（流式文件）：
   2. 有结构文件（记录式文件）：
      1. 有结构文件又可以分为：
         1. 顺序文件：
         2. 索引文件：
            1. 索引表本身式定长记录的顺序文件。
         3. 索引顺序文件：
            1. 概念：顺序和索引的两张组织形式的组合，将顺序文件中的所有记录分为若干组，为顺序文件建立一张**索引表**，在索引表中为每组中的第一条记录建立一个**索引项**，索引项包含该记录的关键字和指向该记录的指针。
            2. 同一组的关键字可以无序，但组与组之间必须有序。
         4. 直接文件（或散列文件）：
            1. 概念：给定记录的键值或通过散列函数转换的键值直接决定记录的物理地址。



### 4.1.2 目录结构

- 实际上就是文件”外部“的逻辑结构的问题。



1. **目录管理的基本要求**：
   1. **按名存取**：从用户的角度看，目录在用户所需要的文件名与文件之间提供一种映射，所以目录管理要实现”按名存取“。
   2. 因为目录存取的效率直接影响到系统的性能，所以**要提高对目录的检索速度**。
   3. 在共享系统里，目录还需要**提供用户控制访问文件的信息**。
2. **文件控制块（FCB）**：文件控制块是用来存放控制文件所需要的各种信息的数据结构，以实现”按名存取“。
   1. 文件目录：文件控制块的有序集合。
   2. 一个 FCB 就是一个文件目录项。
   3. FCB 主要包含的信息：
      1. 基本信息：文件名，文件的物理位置，逻辑结构，物理结构等。
      2. 存取控制信息：文件存取权限等。
      3. 使用信息：文件建立时间、修改时间等。
3. **索引节点**：
   1. 索引节点概念：文件名和文件描述信息分开，文件描述信息单独形成一个称为索引节点的数据结构，简称 **i 节点**。
   2. 索引节点提出的原因：检索目录的时候，只用了文件名，文件的其它描述信息不会用到，也不需要调入内存。
   3. 文件目录的目录项的构成：在文件目录中，每个**目录项**仅由**文件名**和指向该文件所对应的 i 节点的**指构成**。
   4. 注意：FCB 必须连续存放。
   5. 磁盘索引节点：存放在磁盘上的索引节点。
4. **目录结构的分类**：
   1. 单级目录结构：
   2. 两级目录结构：
   3. 多级目录结构（树形目录结构）：
   4. 无环图目录结构：



### 4.1.3 文件共享

1. 文件共享概念：文件共享使多个用户（进程）共享同一个文件，系统中只需要保留该文件的一个副本。
2. 两种文件共享的方法：
   1. **基于索引节点的共享方式（硬链接）**：
      1. 所有用户对共享的文件都有一个指向索引节点的指针，
      2. 在索引节点中设置一个链接计数 count ：用于表示链接到本索引节点上的用户目录项的数目。
      3. 
   2. **利用符号链实现文件共享（软链接）**：
      1. 只有文件拥有者才拥有指向索引节点的指针，而共享该文件的其他用户只有该文件的路径名。
3. 硬链接和软链接都是静态共享方法。
4. 动态共享：两个进程同时对一个文件进行操作。
5. **总结**：
   1. 硬链接：就是多个**指针**指向一个索引节点，保证只要还有一个指针指向索引节点，索引节点就不能删除
   2. 软连接：就是把达到共享文件的**路径**记录下来，当要访问文件时，根据路径寻找文件。
   3. 硬链接的查找速度比软连接快。



### 4.1.4 文件保护（考纲无）

1. 文件保护：通过口令保护、加密保护和访问控制等方式实现。
   1. 口令和加密是防止用户文件被他人窃取
   2. 访问控制是用于控制用户对文件的访问方式。



## 4.2 文件系统的实现

- 文件的实现，就是文件的物理结构。即，文件数据在物理存储设备上是**如何分布和组织的**。
  - 针对这个问题有两方面的回答：
    - 文件的分配方式：对磁盘非空闲块的管理。
    - 文件存储空间管理：对磁盘空闲块的管理。

### 4.2.1 目录实现

1. 目录的实现是为了查找：查找目录项，目录项中提供了查找磁盘块中所需要的信息。
2. 目录实现的基本方法，两种，线性列表和哈希表：
   1. 线性列表：
      1. 概念：最简单的目录实现方法是使用**存储文件名和数据块指针**的线性表。
      2. 优点：采用链表结构可以减少删除文件的时间，优点在于实现简单。
      3. 缺点：由于线性表的特殊性，比较费时。
   2. 哈希表：
      1. 概念：哈希表根据文件名得到一个值，并返回一个指向线性列表中元素的指针。
      2. 优点：查找非常迅速，插入和删除也简单，
      3. 缺点：需要一些预备措施来避免冲突。
      4. 最大的困难：哈希表长度的固定，以及，哈希函数对表厂的依赖性。





### 4.2.2 文件实现-文件分配方式

- 文件分配方式就是对**非空闲块**的分配。
- 常见的文件分配方式有三种：
  - 连续分配
  - 链接分配
  - 索引分配



1. 常用的磁盘空间分配方法有三种：
   1. 连续分配：
      1. 概念：连续分配要求每个文件在磁盘上占有一组**连续的块**。
      2. 磁盘地址定义 了磁盘上的一个先行排序。
      3. 这种排序是使作业访问磁盘时，**需要的寻道数和寻道时间最小**。
      4. 文件连续分配的定义：可以用第一块磁盘的地址和连续块的数量来定义。
      5. 一个文件的**目录条目**：包可 **开始块的地址** 和 **该文件所分配区域的长度**。
      6. 连续分配支持 顺序访问和直接访问。
      7. 优点：实现简单，存取速度快。
      8. 缺点：
         1. 文件长度**不宜动态增加**。
         2. 反复增删文件后会产生 **外部碎片**
         3. 很难确定一个文件需要的空间大小，所以只用于**长度固定的文件**。
   2. **链接分配**：
      1. 概念：链接分配采取里离散分配的方式。
      2. 优点：
         1. 消除了外部碎片，提高了磁盘空间的利用率。
         2. 无需事先知道文件的大小，可以动态给文件分配磁盘块。
      3. 链接分配，分为两种：
         1. **隐式链接**：
            1. 概念：每个文件对应磁盘块的一个链表，即，链表中的指针对用户是**透明的**。
            2. 目录包括：第一块的指针 和 最后一块的指针。
            3. 缺点：
               1. 无法直接访问盘块，只能通过指针顺序访问文件。
               2. 盘块指针对消耗一定的存储空间。
               3. 隐式链接分配的稳定性也是一个问题，如果链表的指针丢失或者损坏，或导致文件数据的丢失。
         2. **显示链接**：
            1. 概念：把用于链接各文件物理块的**指针**，从每个物理块的末尾中**提取出来**，**显式**存放在内存中的一张链表中。
            2. **文件分配表（FAT)** :该表在这个磁盘中**仅设置一块**，称为文件分配表（FAT）。
               1. FAT 每个**表项**：存放对应块的**下一块链接指针**，即，下一个盘块号。
               2. FAT 的表项与全部磁盘块**一一对应**。
               3. 数字 -1 表示文件的**最后一块**。
               4. 数字 -2 表示这个磁盘块**空闲**。
               5. FAT 表在启动时，就会被 **读入内存**。因此，查找 FAT 表是在内存中进行的。
                  1. 显著提高了检索速度，
                  2. 明显减少了访问磁盘的次数。
   3. **索引分配**：
      1. 概念：把每个文件的的**所有盘块号**都集中放在一起构成**索引块（表）**。
      2. 索引分配解决的问题：链接分配解决了连续分配的外部碎片和文件大管理的问题，但是链接链接分配不能**有效支持直接访问**（FAT 除外），索引分配解决了这个问题。
      3. 索引块：
         1. 每个文件都有索引块，这是一个磁盘块的数组。
         2. 索引块的第 i 个条目，指向文件的第 i 块。
         3. 而目录条目则，包含的是，索引块的地址。
      4. 优点：
         1. 支持直接访问，
         2. 没有外部碎片问题。
      5. 缺点：
         1. 因为索引块的分配，增加了系统存储空间的开销。
         2. 索引表的查找策略对文件系统效率影响较大。
      6. 如何**确定索引块的大小**：
         1. 链接方案：将多个索引块链接起来。
         2. 多层索引：使第一层索引块指向第二次索引块，第二场索引块再指向文件块。往后延申。
         3. **混合索引**：将多种索引分配方式相结合的分配方式
            1. 比如：即采用直接地址，又 采用多级索引分配。
            2. UNIX 系统就是采用混合索引分配，UNIX 系统性质如下：
               1. UNIX 有13个地址项：
                  1. 10 个直接地址
                  2. 一个一级索引地址
                  3. 一个二级索引地址
                  4. 一个三级索引地址
      7. 注意：访问文件需要**两次访问外存**
         1. 首先读取索引块的内容
         2. 然后访问具体的磁盘块。
         3. 为了解决这个问题：通常将文件的索引块读入内存的缓冲区，以加快文件的访问速度。





### 4.2.3 文件实现-文件存储空间管理

1. **文件卷**：可以是物理盘块的一部分，也可以是一个或多个物理盘块。
   1. 文件卷分为：
      1. 文件区：文件数据信息的空间。
      2. 目录区：存放文件控制信息（FCB）的空间。
2. 块：文件存储设备分成许多大小相同的物理块，并**以块为单位**交换信息。
3. 文件存储设备的管理**实质**：对**空闲块**的组织和管理，包括空闲块的组织、分配与回收等。



==文件存储空间管理的**分四类**==：

1. 空闲表法：
   1. 空闲表法属于**连续分配**，为每个文件分配一块连续的存储空间。
   2. 系统为外存上的所有**空闲区**建立一个空闲盘块 表，每个空闲区对应一个**空闲表项**，
   3. 空闲表项：包括 表项序号、该空闲区的第一个盘块号，该区的空闲盘块数等信息。
2. 空闲链表法：
   1. 概念：把所有空闲盘区拉成一条**空闲链**。
   2. 空闲链分为两类：
      1. 空闲盘块链：
      2. 空闲盘区链：
      3. 每个盘区可以包含若干盘块。
3. 位示图法：
   1. 概念：利用二进制的一位来表示磁盘中一个盘块的使用情况。
      1. 0 ：对应盘块空闲。
      2. 1 ：对应盘块已分配。
   2. **盘块的分配**：
      1. 顺序扫描位示图，从中找出一个或一组 值为 0 的二进制位。
      2. 转换成对应的盘块号：
         1. $b = n(i -1) + j$
         2. 值在 i 行，j 列，n：每行的位数，b ：盘块号
      3. 修改位示图：$map[i,j] = 1$
   3. **盘块的回收**：
      1. 将回收盘块的盘块号 转换成 位示图的行号和列号，
         1. $i = (b-1) DIV n + 1$
         2. $j = (b-1) MOD n+1$
      2. 修改位示图：$map[i,j] = 0$
4. 成组链接法：
   1. 提出原因 ：空闲表和空闲链表都不适用于大型文件系统。
   2. 概念：结合了空闲表和空闲链表两种方法，克服了表太大的缺点。
   3. 思想：把顺序的 n 个空闲扇区地址保存在第一个空闲扇区内，其最后一个空闲扇区内则保存另一组顺序空闲 扇区的地址。



## 4.3 磁盘组织与管理

### 4.3.1 磁盘的结构（基本名词概念）

1. 磁盘：
2. 磁头：
3. 磁道：
4. 扇区：
5. 盘块：
6. 磁盘组：
7. 柱面：所有盘面上相对位置相同的磁道组成组面。
8. **磁盘地址**：柱面号·盘块号·扇区号（或盘块号，或簇号）
9. **簇**：包含多个扇区（具体根据题意）。





### 4.3.2 磁盘调度算法

#### 1、磁盘读写操作的时间

- 一次磁盘读写操作的时间由 **寻找（寻道）时间、旋转延迟时间、传输时间**决定。



1. 寻找时间（寻道时间） $Ts$ :
   1. 定义：活动头在磁盘读写信息前，将磁头移动到指定磁道所需要的时间。
   2. 计算公式：$Ts = m * n + s$
      1. m : 与磁盘驱动器有关的常数
      2. n : 跨越的 磁道数
      3. s ：启动磁臂的时间
2. 旋转延迟时间 $Tr $:
   1. 定义：磁盘定位到某一磁道的扇区所需要的时间
   2. 计算公式：$Tr = 1 / (2r)$
      1. r : 磁盘的旋转速度
3. 传输时间 $Tt$ :
   1. 定义：从磁盘读出或向磁盘写入数据的时间。
   2. 计算公式：$Tt = b / (rN)$
      1. b ：每次读/写 的字节数
      2. r : 磁盘每秒的转速。
      3. N ：一个磁道上的字节数。
4. **平均总存取时间**：$Ta = Ts + Tr +Tt$



#### 2、磁盘调度算法

1. 先来先服务（FCFS) 算法：（==考纲无==）
   1. 定义：根据进程请求访问磁盘的先后顺序进行调度。
   2. 优点：具有公平性。
   3. 
2. 最短寻找时间优先（Shorted Seek Time First, SSTF) 算法：
   1. 定义：选择调度与当前磁头所在磁道距离最近的磁道。
   2. 特质：
      1. 会产生 **饥饿** 现象：在当前磁道附近频繁增加新的请求，则距离远的磁道的访问将被无限期延迟，即，**饿死**。
3. 扫描（SCAN）算法：（电梯调度算法）
   1. 定义：磁头**在当前移动方向上** 选择与当前磁头最近的。
   2. 特质：对最近扫描过的区域不公平，所以，它在访问局部性方面，不如前两者好。
4. 循环扫描（Circular SCAN, C-SCAN) 算法：
   1. 定义：在扫描算法的基础上，规定 **磁头单向移动** 来提供服务。回返时直接快速移动至始端而不接受任何请求。
   2. 特质：C-SCAN 算法消除了对两端磁道请求的不公平。
   3. LOOK 调度 与 C-LOOK 调度：磁头移动只需到达最远端的一个请求即可返回，不需要到达磁盘端点，这种形式的 SCAN 与 C-SCAN 分别称为  LOOK 与 C-LOOK 调度。
   4. 注意：一般情况下，默认为 LOOK 与 C-LOOK 调度。





> 减少延迟时间

1. 对盘面扇区进行**交替编号**。
2. 对磁盘组中的不同盘面**错位命名**。



# 五、设备管理

## 5.1 I\O 管理

### 5.1.1 I\O 设备的分类

1. 按**使用特性**分类：
   1. 人机交换类外部设备：
   2. 存储设备：
   3. 网络通信设备：
2. 按**传输速率**分类：
   1. 低速设备：
   2. 中速设备：
   3. 高速设备：
3. 按**信息交换**分类：
   1. 块设备：
   2. 字符设备：



### 5.1.2 I\O 控制方式

- 设备管理的主要任务之一：就是控制 设备和内存或处理机之间的数据传送。 
- I\O 设备控制方式：就是 外围设备和内存之间的输入/输出控制方式。分为如下 4 种。
  - 程序直接控制方式
  - 中断驱动方式
  - DMA 方式
  - 通道控制方式（I/O 方式）



1. **程序直接控制方式**：
   1. 思想：
   2. 优点：简单易实现
   3. 缺点：
      1. 由于 CPU 的高速性 和 I\O 设备的低速性，导致了 CPU 大部分时间都在等待，造成了 CPU 资源的极大浪费。
      2. CPU 和 I\O 设备之间只能串行工作，导致 CPU 的利用率极低。
2. **中断驱动方式**：
   1. 思想：允许 I\O 设备**主动打断 CPU 的运行**并请求服务，
   2. 特质：
      1. 数据中的每个字在存储器与 I\O 设备控制器之间的传输**必须经过 CPU**。仍会消耗很多 CPU 的时间。
3. **DMA 方式**：
   1. 基本思想：在 I\O 设备和内存之间 **开辟直接的数据交换通路**，彻底“解放” CPU 。
   2. DMA 的特点：
      1. 基本单位是数据块。
      2. 所传送的数据，是从设备直接送入内存的，或者相反。
      3. 仅在传送一个或多个数据块的**开始和结束时，才需要 CPU 的干预**，整块数据的传送是在 DMA 控制器的控制下完成。
   3. DMA 控制器中的**4类寄存器**：
      1. 命令/状态寄存器 (CR):
      2. 内存地址寄存器(MAR):
      3. 数据寄存器(DR)：
      4. 数据计数器(DC)：
   4. DMA 控制方式 与中断驱动方式的**主要区别**：
      1. 中断 CPU 的时间：
         1. 中断驱动：在**每个**数据需要传输时中断 CPU;
         2. 而DMA : 在所要求传送的一批数据**全部传送结束**时才中断 CPU 。
      2. 数据传送的控制者：
         1. 中断驱动：数据传送实在中断处理时由 **CPU 控制**完成的。
         2. DMA：在 **DMA 控制器**的控制下完成。
4. **通道控制方式**：
   1. I\O 通道：指专门负责输入\输出的处理机。
   2. 特质：
      1. I\O 通道 是 DMA 的进一步发展，进一步减少了 CPU 的干预。
         1. 即把 对一个数据块的读\写为单位的干预，减少为**对一组数据块**的读\写及有关控制和管理为单位的干预。
      2. 同时，又可以实现 CPU ，通道 和 I\O 设备三者的并行操作。
   3. I\O 通道 与 一般处理机的 区别：
      1. 通道指令单一，**没有自己的内存**，通道所执行的通道程序是放在主机的内存中，**即通道与 CPU 共享内存**。
   4. I\O 通道 与 DMA 方式的**区别**：
      1. DMA : 需要 CPU 来控制传输的数据块大小、传输的内存位置；
      2. 通道方式：这些信息由通道控制。
      3. 每个 DMA 控制器对应一台设备与内存传递数据；
      4. 而一个通道 可以控制多台设备与内存的数据交换。

## 5.2 I\O 核心子系统



###  5.2.1 缓冲区

1. 引入磁盘缓冲区的**目的**：
   1. 缓和 CPU 与 I\O 设备间速度不匹配的矛盾。
   2. 减少 对 CPU 的中断频率，放宽 对 CPU 中断响应时间的限制。
   3. 解决基本数据单元大小（即数据粒度）不匹配的问题。
   4. 提高 CPU 与 I\O 之间的并行性。
2. 缓冲区位于内存区域。
3. 缓冲区的特点：
   1. 当**缓冲区**的数据**非空**时，不能往缓冲区冲入数据，**只能**从缓冲区把**数据传出**；
   2. 当**缓冲区为空**时，**可以**往缓冲区**冲入数据**，但必须把缓冲区充满后，才能从缓冲区把数据传出。
4. 缓冲技术**分四类**（根据设置缓冲器的个数分）：
   1. 单缓冲：
      1. 概念：在设备和处理机之间设置一个缓冲区。
      2. **研究**各种缓冲技术的**每块数据的处理时间的技巧**：假设一种初始状态，然后计算下一次达到相同状态所需要的时间，就是处理一块数据所需要的时间。
      3. 单缓冲区的**初始状态**：工作区是满的，缓冲区是空的。
      4. 单缓冲区**处理一块数据的时间**：$max(C,T)+M$
         1. T：从**磁盘**把一块数据**输入缓冲区**的时间。
         2. M：**操作系统**将该缓冲区的数据**传送到用户区**的时间。
         3. C：**CPU** 对这块数据的**处理时间**。
   2. 双缓冲：
      1. 概念：设立两个缓冲区。
      2. 双缓冲区的**初始状态**：工作区是空的，其中一个缓冲区是满的，一个缓冲区是空的。
      3. 双缓冲区**处理一块数据的时间**：$max(C+M,T)$
   3. 循环缓冲：
      1. 概念：包含有多个大小相等的缓冲区，每个缓冲区有一个链接指针指向下一个缓冲区，最后一个缓冲区指针指向第一个缓冲区，多个缓冲区构成一个环形。
   4. 缓冲池：
      1. 概念：由多个系统公用的缓冲区组成。
         1. 缓冲区按其**使用状况**可以形成三个队列：空缓冲队列、装满输入数据的缓冲队列（输入队列）、装满输出数据的缓冲队列（输出队列）。
         2. 还应具有4种缓冲区：用于**收容输入数据**的工作缓冲区、用于**提取输入数据**的工作缓冲区、用于**收容输入数据**的工作缓冲区、用于**提取输入数据**的工作缓冲区。
5. ==缓冲时间计算总结==：
   1. 一般是求单缓冲或者双缓冲的时间，一般是三部分相加：
      1. 先求第一块数据达到初始条件的时间，
      2. 再求 n-1 （块）乘以每块数据处理的时间，
      3. 再加上最后部分的处理时间。



### 5.2.2 设备的分配与回收

1. 设备分配的**总原则**：
2. 从设备特性的**设备分类**：
   1. 独占式设备：
   2. 分时式共享使用设备
   3. 以 SPOOLing 方式使用外部设备。
3. 设备分配的主要**数据结构**：
   1. 设备控制表(DCT)：
      1. 一个设备控制表，就表征一个设备。
   2. 控制器控制表(COCT)：
   3. 通道控制表(CHCT)：
   4. 系统设备表(SDT)：
      1. 整个系统只有一张 SDT。
4. 设备分配的**策略**：
   1. 设备分配**原则**：
   2. 设备分配**方式**：
   3. 设备分配**算法**：
5. 设备分配的**安全性**：
   1. 安全分配方式：每当进程发出 I/O 请求后便进入阻塞状态，直到 I/O 操作完成时才唤醒。
   2. 不安全分配方式：
6. 逻辑设备名到物理设备名的映射：
   1. **设备独立性**：
      1. 概念：是指应用程序独立于具体使用的物理设备。
      2. 目的：为了提高设备分配的灵活性和设备的利用率，方便实现 I/O 重定向，引入了设备独立性。
      3. **实现设备独立性**：在应用程序中使用逻辑设备表名来请求使用某类设备，在系统中设置一张**逻辑设备表（Logical Unit Table, LUT)**,用于将逻辑设备名映射为物理设备名。

### 5.2.3 SPOOLing 系统（假脱机技术）

1. **目的**：为了缓和 CPU 的高速性和 I\O 设备低速性之间的矛盾，引入了脱机输入\输出技术。
2. SPOOLing 的意思：是外部设备同时联机操作，又称 假脱机输入\输出操作，是操作系统中一项**将独占设备改造成共享设备**的技术。
3. **SPOOLing 系统的组成**：
   1. 输入井和输出井：
      1. 在**磁盘上**开辟出两个存储区域。
   2. 输入缓冲区和输出缓冲区：
      1. 在**内存中**开辟的两个缓冲区。
   3. 输入进程和输出进程：
      1. 输入进程：模拟脱机输入时的外围控制机。
         1. 即将用户要求的数据从输入机通过输入缓冲区再送到输入井。
         2. 内存需要数据时，直接将数据从输入井调入内存。
      2. 输出进程：模拟脱机输出时的外围控制机。
         1. 把用户要求的数据先从内存送到输出井，
         2. 待输出设备空闲时，再将输出井中的数据经过输出缓冲区送到输出设备上。
4. SPOOLing 系统的主要**特点**：
   1. 提高了 I\O 的速度；
   2. 将独占设备改造为共享设备；
   3. 实现了虚拟设备的功能。
5. SPOOLing 就是一种**以空间换时间**的技术。



# 六、820真题总结（OS）

1. 题型：
   1. 填空：10分（5道*2）
   2. 选择：20分（10道*2）
   3. 简答：20分
   4. 大题：30分





# THE END